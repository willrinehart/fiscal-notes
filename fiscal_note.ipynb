{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def download_pdfs_from_url(url):\n",
    "    # Create a new instance of the Firefox driver\n",
    "    driver = webdriver.Firefox()\n",
    "\n",
    "    # Load the webpage\n",
    "    driver.get(url)\n",
    "\n",
    "    # Get the page source\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    # Parse the page source using BeautifulSoup\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # Search for all anchor tags with href ending in \".fn.pdf\"\n",
    "    pdf_links = [a['href'] for a in soup.find_all('a', href=True) if a['href'].endswith('.fn.pdf')]\n",
    "\n",
    "    # Base domain\n",
    "    base_domain = \"https://le.utah.gov\"\n",
    "\n",
    "    # Destination folder\n",
    "    destination_folder = \"/Users/yams/Dropbox/Github/fiscal-notes/pdfs/2022/\"\n",
    "\n",
    "    # Ensure the destination folder exists\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Download and save each PDF\n",
    "    for link in pdf_links:\n",
    "        full_url = base_domain + link\n",
    "        response = requests.get(full_url, stream=True)\n",
    "        filename = os.path.join(destination_folder, link.split('/')[-1])\n",
    "        \n",
    "        with open(filename, 'wb') as pdf_file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                pdf_file.write(chunk)\n",
    "\n",
    "    return len(pdf_links)\n",
    "\n",
    "# Loop over the desired range of bill numbers\n",
    "total_pdfs = 0\n",
    "for bill_number in range(1, 261):  # This will loop from SB0001 to SB0010\n",
    "    url = f\"https://le.utah.gov/~2022/bills/static/HB{bill_number:04}.html\"\n",
    "    total_pdfs += download_pdfs_from_url(url)\n",
    "    \n",
    "    # Sleep for 3 seconds\n",
    "    time.sleep(3)\n",
    "\n",
    "print(f\"Downloaded {total_pdfs} PDFs in total to {destination_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved to extracted_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "\n",
    "# Define functions for extraction\n",
    "\n",
    "def extract_section_content(text, section_title):\n",
    "    pattern = re.compile(rf\"{re.escape(section_title)}(.*?)(?=\\\\n[A-Z][a-z]+|\\\\Z)\", re.DOTALL)\n",
    "    matches = pattern.findall(text)\n",
    "    return matches[0].strip() if matches else None\n",
    "\n",
    "def extract_data_from_pdf(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in pdf_document:\n",
    "        text += page.get_text(\"text\")\n",
    "    pdf_document.close()\n",
    "    \n",
    "    # Extracting data based on the sections and format we discussed\n",
    "    geusf = extract_section_content(text, \"General, Education, and Uniform School Funds\")\n",
    "    local_gov = extract_section_content(text, \"Local Government\")\n",
    "    individuals_businesses = extract_section_content(text, \"Individuals & Businesses\")\n",
    "    regulatory_impact = extract_section_content(text, \"Regulatory Impact\")\n",
    "    performance_evaluation = extract_section_content(text, \"Performance Evaluation\")\n",
    "    \n",
    "    return [geusf, local_gov, individuals_businesses, regulatory_impact, performance_evaluation]\n",
    "\n",
    "# Specify the directory containing the PDFs\n",
    "directory_path = '/Users/yams/Dropbox/Github/fiscal-notes/pdfs/'\n",
    "\n",
    "# Loop through each PDF and extract data\n",
    "all_data = []\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(directory_path, filename)\n",
    "        extracted_data = extract_data_from_pdf(pdf_path)\n",
    "        all_data.append(extracted_data)\n",
    "\n",
    "# Write the extracted data to a CSV\n",
    "csv_path = 'extracted_data.csv'\n",
    "with open(csv_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"General, Education, and Uniform School Funds\", \"Local Government\", \"Individuals & Businesses\", \"Regulatory Impact\", \"Performance Evaluation\"])\n",
    "    writer.writerows(all_data)\n",
    "\n",
    "print(f\"Data extracted and saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "\n",
    "# Define functions for extraction\n",
    "\n",
    "def extract_section_content(text, section_title):\n",
    "    pattern = re.compile(rf\"{re.escape(section_title)}(.*?)(?=\\\\n[A-Z][a-z]+|\\\\Z)\", re.DOTALL)\n",
    "    matches = pattern.findall(text)\n",
    "    return matches[0].strip() if matches else None\n",
    "\n",
    "def extract_data_from_pdf(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in pdf_document:\n",
    "        text += page.get_text(\"text\")\n",
    "    pdf_document.close()\n",
    "    \n",
    "    # Print the first 500 characters of the extracted text for debugging\n",
    "    print(\"===== BEGIN EXTRACTED TEXT =====\")\n",
    "    print(text[:500])\n",
    "    print(\"===== END EXTRACTED TEXT =====\")\n",
    "    \n",
    "    # Extracting data based on the sections and format we discussed\n",
    "    geusf = extract_section_content(text, \"General, Education, and Uniform School Funds\")\n",
    "    local_gov = extract_section_content(text, \"Local Government\")\n",
    "    individuals_businesses = extract_section_content(text, \"Individuals & Businesses\")\n",
    "    regulatory_impact = extract_section_content(text, \"Regulatory Impact\")\n",
    "    performance_evaluation = extract_section_content(text, \"Performance Evaluation\")\n",
    "    \n",
    "    return [geusf, local_gov, individuals_businesses, regulatory_impact, performance_evaluation]\n",
    "\n",
    "# Specify the directory containing the PDFs\n",
    "directory_path = '/Users/yams/Dropbox/Github/fiscal-notes/pdfs/'\n",
    "\n",
    "# Loop through each PDF and extract data\n",
    "all_data = []\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(directory_path, filename)\n",
    "        extracted_data = extract_data_from_pdf(pdf_path)\n",
    "        all_data.append(extracted_data)\n",
    "\n",
    "# Write the extracted data to a CSV\n",
    "csv_path = 'extracted_data.csv'\n",
    "with open(csv_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"General, Education, and Uniform School Funds\", \"Local Government\", \"Individuals & Businesses\", \"Regulatory Impact\", \"Performance Evaluation\"])\n",
    "    writer.writerows(all_data)\n",
    "\n",
    "print(all_data)    \n",
    "print(f\"Data extracted and saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Page' object has no attribute 'getText'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m page \u001b[38;5;241m=\u001b[39m doc[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Assuming you're looking at the first page\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Extract blocks of text\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m blocks \u001b[38;5;241m=\u001b[39m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetText\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblocks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Sort blocks based on vertical position\u001b[39;00m\n\u001b[1;32m     10\u001b[0m blocks\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m block: block[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Page' object has no attribute 'getText'"
     ]
    }
   ],
   "source": [
    "\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "doc = fitz.open('/Users/yams/Dropbox/Github/fiscal-notes/pdfs/HB0013.fn.pdf')\n",
    "page = doc[0]  # Assuming you're looking at the first page\n",
    "\n",
    "# Extract blocks of text\n",
    "blocks = page.get_text(\"blocks\")\n",
    "\n",
    "# Sort blocks based on vertical position\n",
    "blocks.sort(key=lambda block: block[1])\n",
    "\n",
    "for block in blocks:\n",
    "    print(block[4])  # This will print the text in each block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved to /Users/yams/Dropbox/Github/fiscal-notes/extracted_data_UT_2022.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "\n",
    "def refined_extract_section_content(text, section_title, end_title):\n",
    "    \"\"\"Extract content between two section titles.\"\"\"\n",
    "    pattern = re.compile(rf\"{re.escape(section_title)}(.*?){re.escape(end_title)}\", re.DOTALL)\n",
    "    matches = pattern.findall(text)\n",
    "    return matches[0].strip() if matches else None\n",
    "\n",
    "def refined_extract_data_from_pdf(pdf_path, section_titles):\n",
    "    \"\"\"Extract data from a PDF using predefined section titles.\"\"\"\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in pdf_document:\n",
    "        text += page.get_text(\"text\")\n",
    "    pdf_document.close()\n",
    "    \n",
    "    sections_content_refined = {}\n",
    "    for i, title in enumerate(section_titles[:-1]):\n",
    "        end_title = section_titles[i+1]\n",
    "        section_content = refined_extract_section_content(text, title, end_title)\n",
    "        sections_content_refined[title] = section_content\n",
    "    \n",
    "    return sections_content_refined\n",
    "\n",
    "# Define a list of expected section titles based on our observations\n",
    "expected_section_titles = [\n",
    "    \"General, Income Tax, and Uniform School Funds\",\n",
    "    \"State Government\",\n",
    "    \"Expenditures\",\n",
    "    \"Individuals & Businesses\",\n",
    "    \"Regulatory Impact\",\n",
    "    \"Performance Evaluation\"\n",
    "    # Further sections can be added as they are identified\n",
    "]\n",
    "\n",
    "# Specify the directory containing the PDFs\n",
    "directory_path = '/Users/yams/Dropbox/Github/fiscal-notes/pdfs/2022/'\n",
    "\n",
    "# Modify the extraction loop to include the filename in the extracted data\n",
    "\n",
    "all_data_refined_with_filename = []\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(directory_path, filename)\n",
    "        extracted_data_refined = refined_extract_data_from_pdf(pdf_path, expected_section_titles)\n",
    "        \n",
    "        # Add the filename to the extracted data\n",
    "        extracted_data_refined['Filename'] = filename\n",
    "        all_data_refined_with_filename.append(extracted_data_refined)\n",
    "\n",
    "# Update the CSV writing part to include the new \"Filename\" field\n",
    "\n",
    "csv_path_with_filename = '/Users/yams/Dropbox/Github/fiscal-notes/extracted_data_UT_2022.csv'\n",
    "\n",
    "with open(csv_path_with_filename, 'w', newline='') as file:\n",
    "    # Adding \"Filename\" to the beginning of the fieldnames list\n",
    "    fieldnames = ['Filename'] + expected_section_titles[:-1]\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    for data in all_data_refined_with_filename:\n",
    "        writer.writerow(data)\n",
    "\n",
    "print(f\"Data extracted and saved to {csv_path_with_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Filename  General, Income Tax, and Uniform School Funds  \\\n",
      "0     HB0084.fn.pdf                                            NaN   \n",
      "1  SB0150S03.fn.pdf                                            NaN   \n",
      "2     HB0233.fn.pdf                                            NaN   \n",
      "3     HB0184.fn.pdf                                            NaN   \n",
      "4     HB0462.fn.pdf                                            NaN   \n",
      "\n",
      "                                    State Government  \\\n",
      "0  UCA 36-12-13(2)(c)\\nRevenues\\nFY 2022\\nFY 2023...   \n",
      "1  UCA 36-12-13(2)(c)\\nRevenues\\nFY 2022\\nFY 2023...   \n",
      "2  UCA 36-12-13(2)(c)\\nRevenues\\nFY 2022\\nFY 2023...   \n",
      "3  UCA 36-12-13(2)(c)\\nRevenues\\nFY 2022\\nFY 2023...   \n",
      "4  UCA 36-12-13(2)(c)\\nRevenues\\nFY 2022\\nFY 2023...   \n",
      "\n",
      "                                        Expenditures  \\\n",
      "0  FY 2022\\nFY 2023\\nFY 2024\\nGeneral Fund\\n$0\\n$...   \n",
      "1  FY 2022\\nFY 2023\\nFY 2024\\nGeneral Fund\\n$0\\n$...   \n",
      "2  FY 2022\\nFY 2023\\nFY 2024\\nGeneral Fund\\n$0\\n$...   \n",
      "3  FY 2022\\nFY 2023\\nFY 2024\\nTotal Expenditures\\...   \n",
      "4  FY 2022\\nFY 2023\\nFY 2024\\nGeneral Fund\\n$0\\n$...   \n",
      "\n",
      "                            Individuals & Businesses  \\\n",
      "0  UCA 36-12-13(2)(c)\\nEnactment of this legislat...   \n",
      "1  UCA 36-12-13(2)(c)\\nEnactment of this legislat...   \n",
      "2  UCA 36-12-13(2)(c)\\nEnactment of this bill may...   \n",
      "3  UCA 36-12-13(2)(c)\\nEnactment of this legislat...   \n",
      "4  UCA 36-12-13(2)(c)\\nEnactment of this legislat...   \n",
      "\n",
      "                                   Regulatory Impact  \n",
      "0  UCA 36-12-13(2)(d)\\nEnactment of this legislat...  \n",
      "1  UCA 36-12-13(2)(d)\\nEnactment of this legislat...  \n",
      "2  UCA 36-12-13(2)(d)\\nEnactment of this legislat...  \n",
      "3  UCA 36-12-13(2)(d)\\nEnactment of this legislat...  \n",
      "4  UCA 36-12-13(2)(d)\\nEnactment of this legislat...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "data_df = pd.read_csv('/Users/yams/Dropbox/Github/fiscal-notes/extracted_data_UT_2022.csv')\n",
    "\n",
    "# Display the first five rows of the DataFrame\n",
    "print(data_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Regulatory Impact\n",
       "UCA 36-12-13(2)(d)\\nEnactment of this legislation likely will not change the regulatory burden for Utah residents or\\nbusinesses.                                                                                                           899\n",
       "UCA 36-12-13(2)(d)\\nEnactment of this legislation could result in a small increase in the regulatory burden for Utah residents\\nor businesses.                                                                                              124\n",
       "UCA 36-12-13(2)(d)\\nEnactment of this legislation could result in a small reduction in the regulatory burden for Utah\\nresidents or businesses.                                                                                              37\n",
       "UCA 36-12-13(2)(d)\\nEnactment of this legislation could result in a medium increase in the regulatory burden for Utah\\nresidents or businesses.                                                                                               8\n",
       "UCA 36-12-13(2)(d)\\nEnactment of this legislation could result in a large increase in the regulatory burden for Utah residents\\nor businesses.                                                                                                2\n",
       "                                                                                                                                                                                                                                           ... \n",
       "UCA 36-12-13(2)(d)\\nEnactment of this legislation likely will not change the regulatory burden for Utah residents or\\nbusinesses.\\nS.B. 169 3rd Sub. (Ivory)\\n2022/03/01 08:01, Lead Analyst: Ivan D. Djambov Attorney: RHR                   1\n",
       "UCA 36-12-13(2)(d)\\nEnactment of this legislation likely will not change the regulatory burden for Utah residents or\\nbusinesses.\\nH.B. 35 1st Sub. (Buff)\\n2022/01/24 11:00, Lead Analyst: Timothy G. Dinehart Attorney: GH                  1\n",
       "UCA 36-12-13(2)(d)\\nEnactment of this legislation could result in a small increase in the regulatory burden for Utah residents\\nor businesses.\\nH.B. 116 1st Sub. (Buff)\\n2022/02/01 18:00, Lead Analyst: Bidusha Mudbhari Attorney: CW1      1\n",
       "UCA 36-12-13(2)(d)\\nEnactment of this legislation likely will not change the regulatory burden for Utah residents or\\nbusinesses.\\nH.B. 201\\n2022/02/16 11:16, Lead Analyst: Steven M. Allred Attorney: CW1                                   1\n",
       "UCA 36-12-13(2)(d)\\nEnactment of this legislation likely will not change the regulatory burden for Utah residents or\\nbusinesses.\\nH.B. 311 3rd Sub. (Cherry)\\n2022/03/02 08:31, Lead Analyst: Andrea Wilko Attorney: CRG                     1\n",
       "Name: count, Length: 235, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "data_df = pd.read_csv('/Users/yams/Dropbox/Github/fiscal-notes/extracted_data_UT_2022.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame to understand its structure\n",
    "data_df.head()\n",
    "\n",
    "# Extract unique values from the \"Regulatory Impact\" column\n",
    "unique_regulatory_impacts = data_df[\"Regulatory Impact\"].dropna().unique()\n",
    "\n",
    "unique_regulatory_impacts\n",
    "\n",
    "# Count the occurrences of each unique value in the \"Regulatory Impact\" column\n",
    "regulatory_impact_counts = data_df[\"Regulatory Impact\"].value_counts()\n",
    "\n",
    "regulatory_impact_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impact Category\n",
      "No change in regulatory burden           1100\n",
      "Small increase in regulatory burden       146\n",
      "Missing Data                               76\n",
      "Small reduction in regulatory burden       40\n",
      "Medium increase in regulatory burden       10\n",
      "Medium reduction in regulatory burden       2\n",
      "Other unique statements                     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def categorize_regulatory_impact(statement):\n",
    "    \"\"\"Categorize the regulatory impact based on specific phrases.\"\"\"\n",
    "    if pd.isna(statement):\n",
    "        return \"Missing Data\"\n",
    "    elif \"not change the regulatory burden\" in statement:\n",
    "        return \"No change in regulatory burden\"\n",
    "    elif \"small increase in the regulatory burden\" in statement:\n",
    "        return \"Small increase in regulatory burden\"\n",
    "    elif \"small reduction in the regulatory burden\" in statement:\n",
    "        return \"Small reduction in regulatory burden\"\n",
    "    elif \"medium increase in the regulatory burden\" in statement:\n",
    "        return \"Medium increase in regulatory burden\"\n",
    "    elif \"medium reduction in the regulatory burden\" in statement:\n",
    "        return \"Medium reduction in regulatory burden\"\n",
    "    else:\n",
    "        return \"Other unique statements\"\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "data_df = pd.read_csv('/Users/yams/Dropbox/Github/fiscal-notes/extracted_data_UT_2022.csv')\n",
    "\n",
    "# Categorize each statement in the \"Regulatory Impact\" column\n",
    "data_df['Impact Category'] = data_df['Regulatory Impact'].apply(categorize_regulatory_impact)\n",
    "\n",
    "# Count the occurrences of each category\n",
    "category_counts = data_df['Impact Category'].value_counts()\n",
    "\n",
    "print(category_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IB Impact Category\n",
       "No direct expenditures from tax/fee changes      972\n",
       "Other unique statements                          389\n",
       "Increase in fines/costs for specific services      9\n",
       "Increase in tax credits for specific groups        3\n",
       "Decrease in costs for specific groups              2\n",
       "Reduction in tax liability                         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize_individuals_businesses(statement):\n",
    "    \"\"\"Categorize the impact on individuals & businesses based on specific phrases.\"\"\"\n",
    "    if pd.isna(statement):\n",
    "        return \"Missing Data\"\n",
    "    elif \"not result in direct expenditures from tax or fee changes\" in statement:\n",
    "        return \"No direct expenditures from tax/fee changes\"\n",
    "    elif \"decrease costs for\" in statement:\n",
    "        return \"Decrease in costs for specific groups\"\n",
    "    elif \"savings for certain offenders\" in statement:\n",
    "        return \"Savings for certain offenders\"\n",
    "    elif \"lead to\" in statement and \"paying\" in statement:\n",
    "        return \"Increase in fines/costs for specific services\"\n",
    "    elif \"individuals could pay additional taxes\" in statement:\n",
    "        return \"Additional tax implications\"\n",
    "    elif \"increase aggregate tax credits\" in statement:\n",
    "        return \"Increase in tax credits for specific groups\"\n",
    "    elif \"decrease sales tax liability\" in statement:\n",
    "        return \"Reduction in tax liability\"\n",
    "    else:\n",
    "        return \"Other unique statements\"\n",
    "\n",
    "# Categorize each statement in the \"Individuals & Businesses\" column\n",
    "data_df['IB Impact Category'] = data_df['Individuals & Businesses'].apply(categorize_individuals_businesses)\n",
    "\n",
    "# Count the occurrences of each category\n",
    "ib_category_counts = data_df['IB Impact Category'].value_counts()\n",
    "\n",
    "ib_category_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yams/Dropbox/Github/fiscal-notes/other_unique_statements.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Filter the DataFrame to get rows where the \"IB Impact Category\" is \"Other unique statements\"\n",
    "other_unique_statements_df = data_df[data_df['IB Impact Category'] == 'Other unique statements']\n",
    "\n",
    "# Extract the \"Individuals & Businesses\" column for these rows\n",
    "other_unique_statements_list = other_unique_statements_df['Individuals & Businesses'].tolist()\n",
    "\n",
    "other_unique_statements_list[:10]  # Display the first 10 for brevity\n",
    "\n",
    "# Save the filtered \"Other unique statements\" to a new CSV file\n",
    "csv_path_unique_statements = '/Users/yams/Dropbox/Github/fiscal-notes/other_unique_statements.csv'\n",
    "other_unique_statements_df[['Filename', 'Individuals & Businesses']].to_csv(csv_path_unique_statements, index=False)\n",
    "\n",
    "csv_path_unique_statements\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
